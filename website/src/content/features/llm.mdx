import { Steps, Tabs } from "nextra/components";

# Large Language Models (LLMs)

Alith provides seamless integration with various **Large Language Models (LLMs)**, allowing you to easily switch between models like GPT-4, GPT-3.5, Claude, DeepSeek and others. Below, you'll find examples of how to initialize and use LLMs in Rust, Python, and Node.js.

<Tabs items={['Rust', 'Python', 'Node.js']}>
  <Tabs.Tab>

## OpenAI Models

Set the API key.

- Unix

```shell
export OPENAI_API_KEY=<your API key>
```

- Windows

```shell
$env:OPENAI_API_KEY = "<your API key>"
```

Write the code.

```rust
use alith::{Agent, LLM};

#[tokio::main]
async fn main() -> Result<(), anyhow::Error> {
    let model = LLM::from_model_name("gpt-4")?;
    let agent = Agent::new("simple agent", model)
        .preamble("You are a comedian here to entertain the user using humour and jokes.");

    let response = agent.prompt("Entertain me!").await?;

    println!("{}", response);

    Ok(())
}
```

## OpenAI API Compatible Models

Here, we take the DeepSeek model as the example.

```rust
use alith::{Agent, LLM};

#[tokio::main]
async fn main() -> Result<(), anyhow::Error> {
    let model = LLM::openai_compatible_model(
        "<Your API Key>", // Replace with your api key or read it from env.
        "api.deepseek.com",
        "deepseek-chat", // or `deepseek-reasoner` for DeepSeek R1 Model
    )?;
    let agent = Agent::new("simple agent", model)
        .preamble("You are a comedian here to entertain the user using humour and jokes.");

    let response = agent.prompt("Entertain me!").await?;

    println!("{}", response);

    Ok(())
}
```

## Anthropic Models

Set the API key.

- Unix

```shell
export ANTHROPIC_API_KEY=<your API key>
```

- Windows

```shell
$env:ANTHROPIC_API_KEY = "<your API key>"
```

Write the code.

```rust
use alith::{Agent, LLM};

#[tokio::main]
async fn main() -> Result<(), anyhow::Error> {
    let model = LLM::from_model_name("claude-3-5-sonnet")?;
    let agent = Agent::new("simple agent", model)
        .preamble("You are a comedian here to entertain the user using humour and jokes.");

    let response = agent.prompt("Entertain me!").await?;

    println!("{}", response);

    Ok(())
}
```

## HuggingFace Models

```rust
use alith::HuggingFaceLoader;

fn main() -> Result<(), anyhow::Error> {
    let _path = HuggingFaceLoader::new().load_file("model.safetensors", "gpt2")?;
    Ok(())
}
```

> Note: we can use the `HF_ENDPOINT` env to set different huggingface endpoints.

## GGUF Models

```rust
use alith::{GgufLoader, GgufLoaderTrait};

fn main() -> Result<(), anyhow::Error> {
    let _model = GgufLoader::default()
        .hf_quant_file_url("https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/blob/main/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf")
        .load()?;

    // By default we attempt to extract everything we need from the GGUF file.
    // If you need to specifiy the tokenizer or chat template to use, you can add a hf repo to load from.
    let _model = GgufLoader::default()
        .hf_quant_file_url("https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/blob/main/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf")
        .hf_config_repo_id("meta-llama/Meta-Llama-3-8B-Instruct")
        .load()?;
    Ok(())
}
```

  </Tabs.Tab>

  <Tabs.Tab>

## OpenAI Models

Set the API key.

- Unix

```shell
export OPENAI_API_KEY=<your API key>
```

- Windows

```shell
$env:OPENAI_API_KEY = "<your API key>"
```

Write the code.

```python
from alith import Agent

agent = Agent(
    name="A dummy Agent",
    model="gpt-4o-mini",
    preamble="You are a comedian here to entertain the user using humour and jokes.",
)
print(agent.prompt("Entertain me!"))
```

## OpenAI API Compatible Models

Here, we take the DeepSeek model as the example.

```python
from alith import Agent

agent = Agent(
    name="A dummy Agent",
    model="deepseek-chat", # or `deepseek-reasoner` for DeepSeek R1
    api_key="<Your API Key>", # Replace with your api key or read it from env.
    base_url="api.deepseek.com",
    preamble="You are a comedian here to entertain the user using humour and jokes.",
)
print(agent.prompt("Entertain me!"))
```

## Anthropic Models

Set the API key.

- Unix

```shell
export ANTHROPIC_API_KEY=<your API key>
```

- Windows

```shell
$env:ANTHROPIC_API_KEY = "<your API key>"
```

Write the code.

```python
from alith import Agent

agent = Agent(
    name="A dummy Agent",
    model="claude-3-5-sonnet",
    preamble="You are a comedian here to entertain the user using humour and jokes.",
)
print(agent.prompt("Entertain me!"))
```

  </Tabs.Tab>

  <Tabs.Tab>

## OpenAI Models

Set the API key.

- Unix

```shell
export OPENAI_API_KEY=<your API key>
```

- Windows

```shell
$env:OPENAI_API_KEY = "<your API key>"
```

Write the code.

```typescript
import { Agent } from "alith";

const agent = new Agent({
  name: "A dummy Agent",
  model: "gpt-4",
  preamble:
    "You are a comedian here to entertain the user using humour and jokes.",
});
console.log(agent.prompt("Entertain me!"));
```

## OpenAI API Compatible Models

Here, we take the DeepSeek model as the example.

```typescript
import { Agent } from "alith";

const agent = new Agent({
  name: "A dummy Agent",
  model: "deepseek-chat", // or `deepseek-reasoner` for DeepSeek R1
  apiKey: "<Your API Key>",
  baseUrl: "api.deepseek.com",
  preamble:
    "You are a comedian here to entertain the user using humour and jokes.",
});
console.log(agent.prompt("Entertain me!"));
```

## Anthropic Models

Set the API key.

- Unix

```shell
export ANTHROPIC_API_KEY=<your API key>
```

- Windows

```shell
$env:ANTHROPIC_API_KEY = "<your API key>"
```

Write the code.

```typescript
import { Agent } from "alith";

const agent = new Agent({
  name: "A dummy Agent",
  model: "claude-3-5-sonnet",
  preamble:
    "You are a comedian here to entertain the user using humour and jokes.",
});
console.log(agent.prompt("Entertain me!"));
```

</Tabs.Tab>
</Tabs>
